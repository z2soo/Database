{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression(binary classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지도학습에서 데이터의 label이 0 혹은 1로 설정\n",
    "이런 데이터는 기존의 선형회귀방식으로는 학습하고 prediction 불가능\n",
    "##### 가설을 바꿈\n",
    "기존가설 H = Wx + b 다중선형회귀에서 사용한 가설 -> 직선\n",
    "직선이 아닌 0에서 1 사이의 값을 가지는 함수로 가설을 표현\n",
    "sigmoid 함수를 이용해서 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 가설이 변경됐기 때문에 해당 가설을 이용한 cost함수를 이용하면 local minima를 찾게 될 여지가 있음.\n",
    "#####cost함수도 변경\n",
    "### cost = ylog(H)-(1-y)log(1-H)  ==> 수학식을 이용해서 cost 함수를"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.00000000e+01 -9.90000000e+00 -9.80000000e+00 -9.70000000e+00\n",
      " -9.60000000e+00 -9.50000000e+00 -9.40000000e+00 -9.30000000e+00\n",
      " -9.20000000e+00 -9.10000000e+00 -9.00000000e+00 -8.90000000e+00\n",
      " -8.80000000e+00 -8.70000000e+00 -8.60000000e+00 -8.50000000e+00\n",
      " -8.40000000e+00 -8.30000000e+00 -8.20000000e+00 -8.10000000e+00\n",
      " -8.00000000e+00 -7.90000000e+00 -7.80000000e+00 -7.70000000e+00\n",
      " -7.60000000e+00 -7.50000000e+00 -7.40000000e+00 -7.30000000e+00\n",
      " -7.20000000e+00 -7.10000000e+00 -7.00000000e+00 -6.90000000e+00\n",
      " -6.80000000e+00 -6.70000000e+00 -6.60000000e+00 -6.50000000e+00\n",
      " -6.40000000e+00 -6.30000000e+00 -6.20000000e+00 -6.10000000e+00\n",
      " -6.00000000e+00 -5.90000000e+00 -5.80000000e+00 -5.70000000e+00\n",
      " -5.60000000e+00 -5.50000000e+00 -5.40000000e+00 -5.30000000e+00\n",
      " -5.20000000e+00 -5.10000000e+00 -5.00000000e+00 -4.90000000e+00\n",
      " -4.80000000e+00 -4.70000000e+00 -4.60000000e+00 -4.50000000e+00\n",
      " -4.40000000e+00 -4.30000000e+00 -4.20000000e+00 -4.10000000e+00\n",
      " -4.00000000e+00 -3.90000000e+00 -3.80000000e+00 -3.70000000e+00\n",
      " -3.60000000e+00 -3.50000000e+00 -3.40000000e+00 -3.30000000e+00\n",
      " -3.20000000e+00 -3.10000000e+00 -3.00000000e+00 -2.90000000e+00\n",
      " -2.80000000e+00 -2.70000000e+00 -2.60000000e+00 -2.50000000e+00\n",
      " -2.40000000e+00 -2.30000000e+00 -2.20000000e+00 -2.10000000e+00\n",
      " -2.00000000e+00 -1.90000000e+00 -1.80000000e+00 -1.70000000e+00\n",
      " -1.60000000e+00 -1.50000000e+00 -1.40000000e+00 -1.30000000e+00\n",
      " -1.20000000e+00 -1.10000000e+00 -1.00000000e+00 -9.00000000e-01\n",
      " -8.00000000e-01 -7.00000000e-01 -6.00000000e-01 -5.00000000e-01\n",
      " -4.00000000e-01 -3.00000000e-01 -2.00000000e-01 -1.00000000e-01\n",
      " -3.55271368e-14  1.00000000e-01  2.00000000e-01  3.00000000e-01\n",
      "  4.00000000e-01  5.00000000e-01  6.00000000e-01  7.00000000e-01\n",
      "  8.00000000e-01  9.00000000e-01  1.00000000e+00  1.10000000e+00\n",
      "  1.20000000e+00  1.30000000e+00  1.40000000e+00  1.50000000e+00\n",
      "  1.60000000e+00  1.70000000e+00  1.80000000e+00  1.90000000e+00\n",
      "  2.00000000e+00  2.10000000e+00  2.20000000e+00  2.30000000e+00\n",
      "  2.40000000e+00  2.50000000e+00  2.60000000e+00  2.70000000e+00\n",
      "  2.80000000e+00  2.90000000e+00  3.00000000e+00  3.10000000e+00\n",
      "  3.20000000e+00  3.30000000e+00  3.40000000e+00  3.50000000e+00\n",
      "  3.60000000e+00  3.70000000e+00  3.80000000e+00  3.90000000e+00\n",
      "  4.00000000e+00  4.10000000e+00  4.20000000e+00  4.30000000e+00\n",
      "  4.40000000e+00  4.50000000e+00  4.60000000e+00  4.70000000e+00\n",
      "  4.80000000e+00  4.90000000e+00  5.00000000e+00  5.10000000e+00\n",
      "  5.20000000e+00  5.30000000e+00  5.40000000e+00  5.50000000e+00\n",
      "  5.60000000e+00  5.70000000e+00  5.80000000e+00  5.90000000e+00\n",
      "  6.00000000e+00  6.10000000e+00  6.20000000e+00  6.30000000e+00\n",
      "  6.40000000e+00  6.50000000e+00  6.60000000e+00  6.70000000e+00\n",
      "  6.80000000e+00  6.90000000e+00  7.00000000e+00  7.10000000e+00\n",
      "  7.20000000e+00  7.30000000e+00  7.40000000e+00  7.50000000e+00\n",
      "  7.60000000e+00  7.70000000e+00  7.80000000e+00  7.90000000e+00\n",
      "  8.00000000e+00  8.10000000e+00  8.20000000e+00  8.30000000e+00\n",
      "  8.40000000e+00  8.50000000e+00  8.60000000e+00  8.70000000e+00\n",
      "  8.80000000e+00  8.90000000e+00  9.00000000e+00  9.10000000e+00\n",
      "  9.20000000e+00  9.30000000e+00  9.40000000e+00  9.50000000e+00\n",
      "  9.60000000e+00  9.70000000e+00  9.80000000e+00  9.90000000e+00]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "x = np.arange(-10,10,0.1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAXAklEQVR4nO3dfZBdd33f8ffXqxWRCEUiEo2th8hMFDd2aMaw47ilD04hWPbEkkMJkZtMSWCiSVu3zYR6ag+M7ZjMpKChnXTihKqEITAU4xCy2TBiNm7iTGY6MbXM+gHZbFkcB+/KxYJYTomFLdnf/nHPwvXde/ee3T336dz3a2ZH957z23t+e+7VZ3/7ezgnMhNJ0ui7YNAVkCRVw0CXpJow0CWpJgx0SaoJA12SamLToA68Y8eO3Ldv36AOL0kj6YEHHvhGZu5st29ggb5v3z5OnDgxqMNL0kiKiL/qtM8uF0mqCQNdkmrCQJekmjDQJakmDHRJqgkDXZJqwkCXpJow0CWpJrouLIqIjwI/CTydmT/SZn8AvwFcCzwH/HxmfrHqikqqh+m5JW6fOcmZs+dW7Lsg4KWEAPp1p4Z+HXP5OBMRvJjJrm1buOnqS7j+8l2VHaPMStGPAb8JfLzD/muA/cXXjwG/XfwrqaZWC+WNeKlI1H7edqdfx1w+zovFTYWWzpzlls8+AlBZqHcN9Mz884jYt0qRQ8DHs3Hro/siYltEXJiZT1VSQ0l91xrYg2g5j4Oz517k6Ox8/wK9hF3Ak03PF4ttKwI9Io4ARwD27t1bwaElbdT03BJHZ+dZOnO2Y2APouU8Lk6dOVvZa1UR6NFmW9v3PTOPAccApqam/GxIA9Ic4s38T9l/F23bUtlrVRHoi8Cepue7gVMVvK6kCnUKcQ3OlskJbrr6ksper4pAnwFujIi7aAyGPmv/uTQcRi3EneWyMWWmLX4KuArYERGLwG3AJEBmfhg4TmPK4gKNaYu/UFntJK3ZKIT49q2T3HbdZZWGmcrNcrmhy/4E/k1lNZK0bu+bfoRP3ve1ylua7VqxhvLwGdgdiyRVpxfzwg3s0WOgSyOuqlZ5L/p01V8GujSiqmiVG+L1YqBLI2ajQW6I15eBLo2Q9XavGOLjwUCXRsB6WuUOao4fA10actNzS9zy2Uc4e+7FUuUD+Nkr9/Jr17++txXT0DHQpSH3q390snSY2yofbwa6NKTW0s1ikAsMdGkole1msXtFzQx0aQiV6WaxVa5WBro0ZKbnlnjmudW7WbZtmWTu1rf2qUYaFRcMugKSvmt6bon33P3QqmW2TE5w+8HL+lQjjRJb6NKQWO43X76JcDt2s2g1Bro0JLr1m9vNom7scpGGQLd+c7tZVIaBLg1Yt37ziQh+/W2vt5tFXRno0gCV6Tf/0Dt+1DBXKQa6NEBl+s0Nc5VloEsDYr+5qmagSwNydHa+4z77zbUeBro0ANNzSyydOdtxv/3mWg8DXeqz5YHQTuw313oZ6FKfrTYQar+5NsJAl/qo20Co/ebaCANd6qPVBkJ3bdtimGtDDHSpT7oNhN509SV9rI3qyECX+sCBUPWDgS71wdHZeQdC1XOlAj0iDkTEfEQsRMTNbfbvjYh7I2IuIh6OiGurr6o0ulbranEgVFXpGugRMQHcCVwDXArcEBGXthR7H3B3Zl4OHAZ+q+qKSqNqem6J6LDPgVBVqUwL/QpgITMfz8wXgLuAQy1lEvg7xeNXA6eqq6I02o7OztPuWoqBA6GqVplA3wU82fR8sdjW7Hbg5yJiETgO/Nt2LxQRRyLiREScOH369DqqK42W1Wa2JNg6V6XKBHq7vxZbGxw3AB/LzN3AtcAnImLFa2fmscycysypnTt3rr220gjpNrNl17YtfayNxkGZQF8E9jQ9383KLpV3A3cDZOZfAN8D7KiigtKo6jazxe4WVa1MoN8P7I+IiyNiM41Bz5mWMl8D3gwQET9MI9DtU9FYc2aL+q1roGfmeeBGYBZ4jMZslpMRcUdEHCyKvQf4xYh4CPgU8POZq9xTS6o5Z7ZoEDaVKZSZx2kMdjZvu7Xp8aPAm6qtmjS6nNmiQXClqNQDp5zZogEw0KWKTc8tcUG073BxZot6yUCXKrQ8VfHFNkNIzmxRrxnoUoU6TVX0ps/qBwNdqlCnvvOXMg1z9ZyBLlVo29bJttsvsu9cfWCgSxWZnlviW98+v2L75ETYd66+MNClihydnefcSysHQ1+5eZPdLeoLA12qwGpXVXz27Lk+10bjykCXNqjbVRXtP1e/GOjSBnlVRQ0LA13aoE5TFcGrKqq/DHRpgzp1qXhVRfWbgS5twPTcEn/7/Mqpina1aBBKXT5X0krLg6Gt/efbt05y23WX2TpX39lCl9ap02DoVueda0AMdGmdOg2GrjZIKvWSgS6tk9dt0bAx0KV18LotGkYGurQOXrdFw8hAl9ahUz+5123RIBno0hqtds9Q+881SAa6tAbeM1TDzECX1sB7hmqYGejSGnjPUA0zA11ag0595PadaxgY6NIa/Pjf20nrcKh95xoWBrpU0vTcEr//wBLNw6EB/PM37rK7RUPBQJdKajcgmsC9Xz49mApJLQx0qSQvxqVhVyrQI+JARMxHxEJE3NyhzDsi4tGIOBkR/6PaakqD5WIijYKuN7iIiAngTuAngEXg/oiYycxHm8rsB24B3pSZz0TEa3tVYanfXEykUVGmhX4FsJCZj2fmC8BdwKGWMr8I3JmZzwBk5tPVVlMaHBcTaVSUCfRdwJNNzxeLbc1+CPihiPhfEXFfRBxo90IRcSQiTkTEidOnHUjSaHAxkUZFmUBv13HY+rfnJmA/cBVwA/CRiNi24psyj2XmVGZO7dy5c611lQbCxUQaFWUCfRHY0/R8N3CqTZk/zMxzmfmXwDyNgJdGnouJNCrKBPr9wP6IuDgiNgOHgZmWMtPAjwNExA4aXTCPV1lRaRBcTKRR0jXQM/M8cCMwCzwG3J2ZJyPijog4WBSbBb4ZEY8C9wI3ZeY3e1VpqV9cTKRR0nXaIkBmHgeOt2y7telxAr9SfEm14WIijRJXikoduJhIo8ZAl9pwMZFGkYEuteFiIo0iA11qw8VEGkUGutSGi4k0igx0qQ0XE2kUGehSCxcTaVQZ6FILFxNpVBnoUgsXE2lUGehSCwdENaoMdKnJ9NwSf/v8+RXbHRDVKCh1LRdpHCyvDm3tP9++dZLbrrvMAVENPVvoUqHT6tCtmzcZ5hoJBrpUcDBUo85AlwoOhmrUGehSwdWhGnUGuoSrQ1UPBrqEq0NVDwa6hAOiqgcDXcIBUdWDga6x5+pQ1YUrRTXWXB2qOrGFrrHm6lDViYGuseZgqOrEQNdY27Z1su12B0M1igx0ja3puSW+9e2Vg6GTE+FgqEaSga6xdXR2nnMv5Yrtr7T/XCPKQNfY6tRP/uzZc32uiVQNA11jy8VEqptSgR4RByJiPiIWIuLmVcq9PSIyIqaqq6JUPRcTqY66BnpETAB3AtcAlwI3RMSlbcq9Cvh3wBeqrqRUpeXFRGdaula2b53k19/2evvPNbLKtNCvABYy8/HMfAG4CzjUptz7gQ8C366wflLlXEykuioT6LuAJ5ueLxbbviMiLgf2ZObnVnuhiDgSESci4sTp016WVIPhYiLVVZlAb72JC/Dd+wBExAXAfwHe0+2FMvNYZk5l5tTOnTvL11KqkIOhqqsygb4I7Gl6vhs41fT8VcCPAH8WEU8AVwIzDoxqWHmrOdVVmUC/H9gfERdHxGbgMDCzvDMzn83MHZm5LzP3AfcBBzPzRE9qLG2At5pTnXUN9Mw8D9wIzAKPAXdn5smIuCMiDva6glKVvNWc6qzU9dAz8zhwvGXbrR3KXrXxakm94YCo6syVohob03NLXBDtxvgdEFU9GOgaC8uLiV7MlRfjckBUdWGgayx0Wkw0EeHqUNWGga6x0KmP/KVMw1y1YaBrLHhnIo0DA121552JNC4MdNWedybSuDDQVXvemUjjwkBX7XkxLo0LA1215p2JNE5KLf2XRtHyYqLW+efbt05y23WX2X+u2rGFrtryzkQaNwa6assLcWncGOiqJS/EpXFkoKt2vBCXxpWBrtrxQlwaVwa6ascLcWlcGeiqHS/EpXFloKtWvBCXxpmBrlrxQlwaZwa6amN6boklL8SlMWagqxaWpyp2Yv+5xoGBrlroNFURnHuu8WGgqxZWW87v3HONCwNdtdBpquKubVsMc40NA10jz6mKUoOBrpHnVEWpwUDXSHOqovRdBrpGllMVpZcz0DWynKoovVypQI+IAxExHxELEXFzm/2/EhGPRsTDEfEnEfED1VdVerlOXS3gVEWNp66BHhETwJ3ANcClwA0RcWlLsTlgKjP/PvAZ4INVV1RqNj23RPv7ETlVUeOrTAv9CmAhMx/PzBeAu4BDzQUy897MfK54eh+wu9pqSi93dHaelfNaIMCuFo2tMoG+C3iy6flisa2TdwOfb7cjIo5ExImIOHH69OnytZSarDazJcHWucZWmUBv95dtu8YREfFzwBRwtN3+zDyWmVOZObVz587ytZQK3Wa27HJmi8bYphJlFoE9Tc93A6daC0XEW4D3Av80M5+vpnrSyzmzReqsTAv9fmB/RFwcEZuBw8BMc4GIuBz4b8DBzHy6+mpKDc5skTrrGuiZeR64EZgFHgPuzsyTEXFHRBwsih0Fvhf4vYh4MCJmOryctG7ObJFWV6bLhcw8Dhxv2XZr0+O3VFwvaQVntkirc6WoRoIzW6TuDHQNPWe2SOUY6Bp6v/pHJ53ZIpVgoGuoTc8t8cxznS+D68wW6bsMdA2t6bkl3nP3Qx33O7NFejkDXUNpud/8xWy7KBlwZovUykDXUFqt3xxg25ZJW+dSCwNdQ6dbv/mWyQluP3hZH2skjQYDXUOlW7/5RIQDoVIHBrqGRpl+8w+940cNc6kDA11Dw35zaWMMdA0F+82ljTPQNXD2m0vVKHW1RalX3jf9CJ+872vtb4FVsN9cKscWugZmem6pa5jbby6VZ6BrIJa7WVYLc/vNpbWxy0V9V6abxX5zae0MdPXN9NwSt8+c5MzZzrNZoHEHIvvNpbUz0NVzZYMcGmH+s1fuNcyldTDQ1VNluleWTUTYMpc2wEBXT6ylVQ52s0hVMNBVubW0ysFuFqkqBroqsdYW+bLtWye57brLDHOpAga6NsQgl4aHga41m55b4ujsPEtnzq75e5e7V37t+tdXXzFpzBno6mq9rfBWtsql3jLQ9TLNre+A0gObq7FVLvWHgT6mWlvdFwS81JLeVYS5rXKpfwz0EVdVi7o1zDfKIJf6r1SgR8QB4DeACeAjmfmfWva/Avg48Ebgm8DPZOYT1Va1c3gtty6r6iLopF/HWe8x+1WnTuxakQara6BHxARwJ/ATwCJwf0TMZOajTcXeDTyTmT8YEYeBDwA/U2VFl28gvHzPyebwWm5d9jrQ+nWcQR9zPXZt28JNV19ii1waoDIt9CuAhcx8HCAi7gIOAc2Bfgi4vXj8GeA3IyIyV7l9+xodnZ1f9QbC6p/lvxoMcWm4lAn0XcCTTc8XgR/rVCYzz0fEs8D3Ad9oLhQRR4AjAHv37l1TRU+tY86zqmOfuDT8ygR6tNnW2vIuU4bMPAYcA5iamlpT6/2ibVvWtZBF5Sy3uicieDHT1rc0gsoE+iKwp+n5buBUhzKLEbEJeDXw15XUsHDT1Ze8rA9dG2erW6qXMoF+P7A/Ii4GloDDwL9oKTMDvBP4C+DtwJ9W2X8OfCd0nOXSfr8takldA73oE78RmKUxbfGjmXkyIu4ATmTmDPA7wCciYoFGy/xwLyp7/eW7DCxJ6qDUPPTMPA4cb9l2a9PjbwM/XW3VJElrccGgKyBJqoaBLkk1YaBLUk0Y6JJUEwa6JNWEgS5JNWGgS1JNRMULOssfOOI08Ffr/PYdtFz4a4gMa92s19pYr7Ub1rrVrV4/kJk72+0YWKBvREScyMypQdejnWGtm/VaG+u1dsNat3Gql10uklQTBrok1cSoBvqxQVdgFcNaN+u1NtZr7Ya1bmNTr5HsQ5ckrTSqLXRJUgsDXZJqYmgDPSJ+OiJORsRLETHVsu+WiFiIiPmIuLrD918cEV+IiK9ExKcjYnOP6vnpiHiw+HoiIh7sUO6JiHikKHeiF3VpOd7tEbHUVLdrO5Q7UJzHhYi4uQ/1OhoRX46IhyPiDyJiW4dyfTlf3X7+iHhF8R4vFJ+nfb2qS9Mx90TEvRHxWPF/4N+3KXNVRDzb9P7e2u61elS/Vd+baPivxTl7OCLe0Ic6XdJ0Lh6MiL+JiF9uKdOXcxYRH42IpyPiS03bXhMR9xR5dE9EbO/wve8synwlIt655oNn5lB+AT8MXAL8GTDVtP1S4CHgFcDFwFeBiTbffzdwuHj8YeBf9aHOHwJu7bDvCWBHH8/f7cB/6FJmojh/rwM2F+f10h7X663ApuLxB4APDOp8lfn5gX8NfLh4fBj4dB/euwuBNxSPXwX8nzb1ugr4XL8+T2t5b4Brgc/TuHPilcAX+ly/CeD/0liA0/dzBvwT4A3Al5q2fRC4uXh8c7vPPfAa4PHi3+3F4+1rOfbQttAz87HMnG+z6xBwV2Y+n5l/CSwAVzQXiIgA/hnwmWLT7wLX97K+xTHfAXyql8ep2BXAQmY+npkvAHfROL89k5l/nJnni6f30bjp+KCU+fkP0fj8QOPz9Obive6ZzHwqM79YPP5/wGPAKN178RDw8Wy4D9gWERf28fhvBr6ametdib4hmfnnNG7F2az5c9Qpj64G7snMv87MZ4B7gANrOfbQBvoqdgFPNj1fZOWH/fuAM03B0a5M1f4x8PXM/EqH/Qn8cUQ8EBFHelyXZTcWf/J+tMOfeGXOZS+9i0ZLrp1+nK8yP/93yhSfp2dpfL76oujiuRz4Qpvd/yAiHoqIz0fEZf2qE93fm0F/rg7TuWE1qHP2dzPzKWj8wgZe26bMhs9bqXuK9kpE/E/g+9vsem9m/mGnb2uzrXXuZZkypZWs5w2s3jp/U2aeiojXAvdExJeL3+Trtlq9gN8G3k/j534/je6gd7W+RJvv3fA81jLnKyLeC5wHPtnhZSo/X+2q2mZbTz9LaxER3wv8PvDLmfk3Lbu/SKNL4VvF+Mg0sL8f9aL7ezPIc7YZOAjc0mb3IM9ZGRs+bwMN9Mx8yzq+bRHY0/R8N3Cqpcw3aPyZt6loVbUrU1q3ekbEJuBtwBtXeY1Txb9PR8Qf0Phzf0MBVfb8RcR/Bz7XZleZc1l5vYrBnp8E3pxF52Gb16j8fLVR5udfLrNYvM+vZuWf05WLiEkaYf7JzPxs6/7mgM/M4xHxWxGxIzN7fhGqEu9NTz5XJV0DfDEzv966Y5DnDPh6RFyYmU8V3U9PtymzSKOff9luGmOIpY1il8sMcLiYfXAxjd+w/7u5QBES9wJvLza9E+jU4q/CW4AvZ+Ziu50R8cqIeNXyYxoDg19qV7YqLX2WP9XhePcD+6MxI2gzjT9VZ3pcrwPAfwQOZuZzHcr063yV+flnaHx+oPF5+tNOv4SqUvTR/w7wWGb+5w5lvn+5Lz8irqDxf/mbvaxXcawy780M8C+L2S5XAs8udzf0Qce/lAd1zgrNn6NOeTQLvDUithddpG8ttpXX6xHfDYwU/xSN31jPA18HZpv2vZfG7IR54Jqm7ceBi4rHr6MR9AvA7wGv6GFdPwb8Usu2i4DjTXV5qPg6SaProdfn7xPAI8DDxYfpwtZ6Fc+vpTGL4qt9qtcCjX7CB4uvD7fWq5/nq93PD9xB4xcOwPcUn5+F4vP0uj6co39E40/th5vO07XALy1/zoAbi3PzEI3B5X/Y63qt9t601C2AO4tz+ghNs9R6XLetNAL61U3b+n7OaPxCeQo4V2TYu2mMu/wJ8JXi39cUZaeAjzR977uKz9oC8AtrPbZL/yWpJkaxy0WS1IaBLkk1YaBLUk0Y6JJUEwa6JNWEgS5JNWGgS1JN/H/a0A27UpG7cAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = 1 / (1 + np.exp(-x))\n",
    "\n",
    "# 시그모이드 함수\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#사용할 데이터는 공부기간 어학연수기간 시험성적\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost값은: 1.1718705892562866\n",
      "cost값은: 0.3176365792751312\n",
      "cost값은: 0.2790791988372803\n",
      "cost값은: 0.26033347845077515\n",
      "cost값은: 0.2490604668855667\n",
      "cost값은: 0.24143807590007782\n",
      "cost값은: 0.23589208722114563\n",
      "cost값은: 0.23165060579776764\n",
      "cost값은: 0.2282881885766983\n",
      "cost값은: 0.2255493402481079\n",
      "시험에 통과: [[0.96883774]]\n"
     ]
    }
   ],
   "source": [
    "# training data set\n",
    "x_data = [[1,1],\n",
    "         [2,0],\n",
    "         [5,1],\n",
    "         [5,1],\n",
    "         [3,3],\n",
    "         [8,1],\n",
    "         [10,0]]\n",
    "y_data = [[0],[0],[0],[1],[1],[1],[1]]\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2],dtype = tf.float32)\n",
    "Y = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "                          \n",
    "# Weight / bias\n",
    "W = tf.Variable(tf.random_normal([2,1]), name = \"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name = \"bias\")\n",
    "                          \n",
    "# Hypothesis\n",
    "logit = tf.matmul(X,W) + b # sigmoid를 이용해서 곡선으로 표현\n",
    "H = tf.sigmoid(logit) #\n",
    "\n",
    "\n",
    "# cost Function ( 일반적으로 텐서플로우에서 제공하는 함수를 이용)\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits =  logit, labels =Y))\n",
    "\n",
    "#T rain \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Session 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "# 학습\n",
    "\n",
    "for step in range(3000):\n",
    "    _, cost_val =  sess.run([train, cost], feed_dict =  {X:x_data,Y:y_data})\n",
    "    if step % 300 == 0 :\n",
    "        print(\"cost값은: {}\".format(cost_val))\n",
    "        \n",
    "        \n",
    "# predict\n",
    "result = sess.run(H, feed_dict = {X: [[8,1]]})\n",
    "\n",
    "if result > 0.5:\n",
    "    print(\"시험에 통과: {}\".format(result))\n",
    "else:\n",
    "    print(\"시험에떨어짐: {}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 대학원 입학시험 예측\n",
    "## 데이터는 admission.csv\n",
    "## logistic regression 수행 -> prediction 진행\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/student/Desktop/Python_Machine Learning/admission.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost값은: 0.9566769599914551\n",
      "cost값은: 0.6904340982437134\n",
      "cost값은: 0.6669344902038574\n",
      "cost값은: 0.6571627259254456\n",
      "cost값은: 0.6491552591323853\n",
      "cost값은: 0.642081618309021\n",
      "cost값은: 0.635796070098877\n",
      "cost값은: 0.6302061676979065\n",
      "cost값은: 0.6252318024635315\n",
      "cost값은: 0.6208013296127319\n"
     ]
    }
   ],
   "source": [
    "x_data = df[[\"gre\",\"gpa\",\"rank\"]]\n",
    "x_data = MinMaxScaler().fit_transform(x_data)\n",
    "y_data = df[[\"admit\"]]\n",
    "y_data = MinMaxScaler().fit_transform(y_data)\n",
    "\n",
    "X = tf.placeholder(shape=[None,3],dtype = tf.float32)\n",
    "Y = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3,1]), name = \"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name = \"bias\")\n",
    "\n",
    "logit = tf.matmul(X,W) + b \n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits =  logit, labels =Y))\n",
    "\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "for step in range(3000):\n",
    "    _, cost_val =  sess.run([train, cost], feed_dict =  {X:x_data,Y:y_data})\n",
    "    if step % 300 == 0 :\n",
    "        print(\"cost값은: {}\".format(cost_val))\n",
    "        \n",
    "        \n",
    "# predict\n",
    "result = sess.run(H, feed_dict = {X: [[500,3.5,2]]})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if result :\n",
    "#     print(\"대학원 합격: {}\".format(result))\n",
    "# else:\n",
    "#     print(\"대학원 불합격: {}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 측정 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 선생 답안\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>admit</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.184434</td>\n",
       "      <td>0.178212</td>\n",
       "      <td>-0.242513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gre</th>\n",
       "      <td>0.184434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.384266</td>\n",
       "      <td>-0.123447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpa</th>\n",
       "      <td>0.178212</td>\n",
       "      <td>0.384266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.057461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>-0.242513</td>\n",
       "      <td>-0.123447</td>\n",
       "      <td>-0.057461</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          admit       gre       gpa      rank\n",
       "admit  1.000000  0.184434  0.178212 -0.242513\n",
       "gre    0.184434  1.000000  0.384266 -0.123447\n",
       "gpa    0.178212  0.384266  1.000000 -0.057461\n",
       "rank  -0.242513 -0.123447 -0.057461  1.000000"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/student/Desktop/Python_Machine Learning/admission.csv\")\n",
    "df.corr() # 상관관계 확인을 통해 전처리\n",
    "# rank값을 조절해야함 --> 음의 상관관계\n",
    "# 역순 정렬 ( 4 ->1 , 3 ->2, 2 ->3, 1->4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_rank(k):\n",
    "    if  k == 4:\n",
    "        return 1\n",
    "    elif k == 3:\n",
    "        return 2\n",
    "    elif k == 2:\n",
    "        return 3\n",
    "    elif k == 1:\n",
    "        return 4\n",
    "\n",
    "\n",
    "df[\"rank\"] = df[\"rank\"].apply(lambda x: change_rank(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit    0\n",
       "gre      0\n",
       "gpa      0\n",
       "rank     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 처리\n",
    "df.isnull().sum() # 결측치 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_outlier(tmp_df,tmp):\n",
    "    q1,q3 = np.percentile(tmp,[25,75])\n",
    "    iqr = q3 - q1\n",
    "    upper = q3 + iqr * 1.5 # 상위임계치\n",
    "    lower = q1 - iqr * 1.5 # 하위임계치\n",
    "    upper_mask = tmp > upper\n",
    "    lower_mask = tmp < lower\n",
    "    \n",
    "    result_mask = upper_mask | lower_mask\n",
    "    return tmp_df[~result_mask]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 4)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이상치 처리\n",
    "df = process_outlier(df,df[\"gre\"])\n",
    "df = process_outlier(df,df[\"gpa\"])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost값은: 0.6634458899497986\n",
      "cost값은: 0.6458544135093689\n",
      "cost값은: 0.6410601735115051\n",
      "cost값은: 0.637378990650177\n",
      "cost값은: 0.6339752674102783\n",
      "cost값은: 0.6307746767997742\n",
      "cost값은: 0.6277612447738647\n",
      "cost값은: 0.6249239444732666\n",
      "cost값은: 0.6222521662712097\n",
      "cost값은: 0.6197361946105957\n",
      "cost값은: 0.6173667311668396\n",
      "cost값은: 0.6151350140571594\n",
      "cost값은: 0.613032877445221\n",
      "cost값은: 0.6110523343086243\n",
      "cost값은: 0.6091859936714172\n",
      "cost값은: 0.6074270009994507\n",
      "cost값은: 0.6057690382003784\n",
      "cost값은: 0.6042056083679199\n",
      "cost값은: 0.6027310490608215\n",
      "cost값은: 0.6013401746749878\n",
      "cost값은: 0.600027859210968\n",
      "cost값은: 0.5987892746925354\n",
      "cost값은: 0.5976197719573975\n",
      "cost값은: 0.5965156555175781\n",
      "cost값은: 0.5954726338386536\n",
      "cost값은: 0.594487190246582\n",
      "cost값은: 0.593555748462677\n",
      "cost값은: 0.5926753282546997\n",
      "cost값은: 0.591842770576477\n",
      "cost값은: 0.591055154800415\n",
      "cost값은: 0.5903100967407227\n",
      "cost값은: 0.589604914188385\n",
      "cost값은: 0.5889374017715454\n",
      "cost값은: 0.5883051753044128\n",
      "cost값은: 0.5877065658569336\n",
      "cost값은: 0.587139368057251\n",
      "cost값은: 0.5866017937660217\n",
      "cost값은: 0.5860921144485474\n",
      "cost값은: 0.5856090188026428\n",
      "cost값은: 0.5851508975028992\n",
      "cost값은: 0.5847162008285522\n",
      "cost값은: 0.5843037962913513\n",
      "cost값은: 0.5839123129844666\n",
      "cost값은: 0.5835406184196472\n",
      "cost값은: 0.5831878781318665\n",
      "cost값은: 0.5828527808189392\n",
      "cost값은: 0.5825343728065491\n",
      "cost값은: 0.5822317600250244\n",
      "cost값은: 0.5819443464279175\n",
      "cost값은: 0.5816711783409119\n",
      "cost값은: 0.5814113020896912\n",
      "cost값은: 0.5811641812324524\n",
      "cost값은: 0.580929160118103\n",
      "cost값은: 0.5807055830955505\n",
      "cost값은: 0.5804927945137024\n",
      "cost값은: 0.5802904367446899\n",
      "cost값은: 0.5800976753234863\n",
      "cost값은: 0.5799141526222229\n",
      "cost값은: 0.5797393918037415\n",
      "cost값은: 0.5795729756355286\n",
      "cost값은: 0.5794145464897156\n",
      "cost값은: 0.5792635083198547\n",
      "cost값은: 0.5791196227073669\n",
      "cost값은: 0.578982412815094\n",
      "cost값은: 0.5788518786430359\n",
      "cost값은: 0.5787271857261658\n",
      "cost값은: 0.578608512878418\n",
      "cost값은: 0.5784951448440552\n",
      "cost값은: 0.5783870816230774\n",
      "cost값은: 0.5782840847969055\n",
      "cost값은: 0.5781857967376709\n",
      "cost값은: 0.5780920386314392\n",
      "cost값은: 0.5780025720596313\n",
      "cost값은: 0.577917218208313\n",
      "cost값은: 0.5778355598449707\n",
      "cost값은: 0.5777578353881836\n",
      "cost값은: 0.5776835083961487\n",
      "cost값은: 0.5776125192642212\n",
      "cost값은: 0.5775448679924011\n",
      "cost값은: 0.577480137348175\n",
      "cost값은: 0.5774184465408325\n",
      "cost값은: 0.5773593783378601\n",
      "cost값은: 0.5773030519485474\n",
      "cost값은: 0.5772492289543152\n",
      "cost값은: 0.577197790145874\n",
      "cost값은: 0.5771485567092896\n",
      "cost값은: 0.5771015882492065\n",
      "cost값은: 0.5770566463470459\n",
      "cost값은: 0.5770137310028076\n",
      "cost값은: 0.5769727230072021\n",
      "cost값은: 0.5769334435462952\n",
      "cost값은: 0.5768960118293762\n",
      "cost값은: 0.5768601298332214\n",
      "cost값은: 0.576825737953186\n",
      "cost값은: 0.5767929553985596\n",
      "cost값은: 0.5767615437507629\n",
      "cost값은: 0.5767316222190857\n",
      "cost값은: 0.576702892780304\n",
      "cost값은: 0.5766753554344177\n",
      "cost값은: 0.5766491889953613\n"
     ]
    }
   ],
   "source": [
    "# 머신러닝\n",
    "x_data = df[[\"gre\",\"gpa\",\"rank\"]].values\n",
    "x_data = MinMaxScaler().fit_transform(x_data)\n",
    "y_data = df[\"admit\"].values.reshape(-1,1)\n",
    "\n",
    "#플홀\n",
    "X = tf.placeholder(shape = [None,3], dtype =tf.float32)\n",
    "Y = tf.placeholder(shape = [None,1], dtype= tf.float32)\n",
    "\n",
    "#\n",
    "W = tf.Variable(tf.random_normal([3,1]), name = \"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name = \"bias\")\n",
    "\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits =  logit, labels =Y))\n",
    "\n",
    "ptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "for step in range(30000):\n",
    "    _, cost_val =  sess.run([train, cost], feed_dict =  {X:x_data,Y:y_data})\n",
    "    if step % 300 == 0 :\n",
    "        print(\"cost값은: {}\".format(cost_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.701265811920166\n"
     ]
    }
   ],
   "source": [
    "## 정확도 측정(Accuracy)\n",
    "## Test Data set 존재 X\n",
    "# train dataset을 test data test로 사용\n",
    "\n",
    "predict = tf.cast(H > 0.5, dtype =tf.float32)\n",
    "correct = tf.equal(predict,Y) # TRUE, FALSE, TRUE, TRUE\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print(\"정확도: {}\".format(sess.run(accuracy, feed_dict={X:x_data,Y:y_data})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[CPU_ENV]",
   "language": "python",
   "name": "cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
