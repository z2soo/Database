{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지금까지 다룬 머신러닝, 기계학습 중 기억할 부분!\n",
    "\n",
    "\n",
    "# 1. learning rate\n",
    "# csot 값을 떨어뜨리기 위함\n",
    "# 정해진 값은 없음\n",
    "# 만약 learning rate가 크다면 overshoot현상이 발생\n",
    "\n",
    "# cost 함수에서 최소가 되는 때의 W 값을 아는 것이 목적\n",
    "# 현재 W - (learnign rate * 기울기 ) 과정으로 수행하면서 적합한 W를 찾아감\n",
    "# 그런데 learnign rate * 기울기 값이 큰 경우 반대편으로 뛰게 됨\n",
    "# cost 값을 기준으로 커스터마이징을 해야 한다.\n",
    "# 너무 작다면 local minimum 혀ㅛㄴ상 발생\n",
    "\n",
    "# 2. 입력 데이터의 pre processing\n",
    "# feature engineering을 포함해서 각 데이터의 범주와 크기를 살펴봐야 한다.\n",
    "# 정규화(normalization: x의 최대, 최소값을 가지고 scale 한다 해서 Min Max Scale 이라고도 함)\n",
    "# 표준화(standardlization: 분산과 표준 편차를 이용해서 값을 sclae 하는 방식)\n",
    "\n",
    "\n",
    "# 3. overfitting (과적합) 현상\n",
    "# 모델을 만들어서 학습을 하는데, 이것이 학습 데이터에 너무 잘 들어맞는 모델이 형성되는 것\n",
    "# 좋다고 생각할 수 있으나 아님!\n",
    "# 델이 학습데이터에 꼭 맞춰진다면 특수한 현상에 대해 맞춤된 모델이 된 것\n",
    "# 원래 목적은 예측을 하는 것, 즉 실제 데이터를 적용할 때, 결과값 예측이 잘 안되는 경우를 의미\n",
    "\n",
    "# 과적합 현상을 피하기 위한 방법!\n",
    "# 1) 많은 training data set이 있어야 한다. : 적을수록 과적합 가능성 높아짐\n",
    "# 2) feature(column)의 갯수를 가능한 줄여야 한다. : \n",
    "\n",
    "\n",
    "# 4. 학습과정\n",
    "# 일반적으로 training data set의 크기가 굉장히 크다\n",
    "# 따라서 1 epoch을 수행하는 시간이 오래 걸려요\n",
    "# 따라서 epoch을 많이 수행시킬 수 없고, batch 처리를 통해 학습을 진행해야 한다.\n",
    "\n",
    "\n",
    "# 5. 정확도\n",
    "# 일반적으로 raw data set을 우리가 얻게 되면, traininf data set, test data set으로 분히(7:3, 8:2)\n",
    "# 평가가 이루어지지 않으면 우리가 만든 모델이 정확한지 알 길이 없음\n",
    "# n fold cross validation: 교차 검증의 과정을 사용하기도 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지금 사용하고 있는 tensorflow는 cpu 버전\n",
    "# deep learning으로 가면 더 많은 수학적 연산(matrix)이 필요하고,\n",
    "# gpu 버전을 사용해서 더 빠르게 게산을 할 수 있다.\n",
    "# 새로운 가상환경을만들어서 tensorflow GPU 버전을 이용해 보기\n",
    "# 이를 위해 비디오 버전이 받쳐줘야 함\n",
    "\n",
    "# 현재 가상환경의 이름: cpu_env\n",
    "# 새로운 가상환경의 이름: gpu_env: mbdr 그래픽 카드, 라데온이나 내장 다른것\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 프로그램 설치\n",
    "# 첫번째 파일: NVIDIA에서 제공하는 최신 비디오 드라이버\n",
    "# 두번째 파일: NVIDIA에서 제공하는 GPU를 쓸 수 있도록 만든 라이브러리\n",
    "# 상세 부분은 블로그 참조\n",
    "\n",
    "# 2. 새로운 가상환경을 하나 생성 및 전환\n",
    "# conda create -n gpu_env python=3.6 openssl\n",
    "# activate gpu_env\n",
    "\n",
    "# 3. nb_conda 설치\n",
    "# 이를 설치해야지 주피터 노트북에서 gpu_env 등록이 된다.\n",
    "# 프롬프트 > conda install nb_conda\n",
    "\n",
    "# 4. kernel 설정\n",
    "# 주피터 kernel에 뜨도록 설정\n",
    "# prompt 관리자 > python -m ipykernel install --user --name=gpu_env --display-name=[GPU_ENV]\n",
    "\n",
    "# 5. 모듈 설치\n",
    "# prompt 관리자 > activate gpu_env > pip install numpy\n",
    "# prompt 관리자 > activate gpu_env > pip install matplotlib\n",
    "# prompt 관리자 > activate gpu_env > pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소프트웨어 측면: 인공지능(AI)\n",
    "# 하드웨어 측면: 양가이론, 양자컴퓨터\n",
    "\n",
    "# 양자컴퓨터가 인공지능이랑 결합되면서 실제 실현 가능한 부분이 됨\n",
    "# 우리가 이야기 할 부분은 인공지능\n",
    "\n",
    "# 컴퓨터 CS측면의 궁극의 목표 중 하나\n",
    "# 스스로 생각하는 컴퓨터를 만들어 보자\n",
    "\n",
    "# 문제점도 존재함\n",
    "# 일자리 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost값은:1.185912847518921\n",
      "cost값은:0.057107001543045044\n",
      "cost값은:0.029160652309656143\n",
      "cost값은:0.019454138353466988\n",
      "cost값은:0.014564098790287971\n",
      "cost값은:0.011627193540334702\n",
      "cost값은:0.009670944884419441\n",
      "cost값은:0.008275598287582397\n",
      "cost값은:0.007230738177895546\n",
      "cost값은:0.006419274490326643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AND/OR에 대한 logistic regression => perceptron\n",
    "# 진리표를 이용해서 학습할 것\n",
    "\n",
    "# 다음은 AND gate\n",
    "import tensorflow as tf\n",
    "\n",
    "x_data = [[0,0],\n",
    "         [0,1],\n",
    "         [1,0],\n",
    "         [1,1]]\n",
    "y_data = [[0],\n",
    "         [0],\n",
    "         [0],\n",
    "         [1]]\n",
    "\n",
    "# X, Y\n",
    "X = tf.placeholder(shape=(None,2), dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=(None,1), dtype=tf.float32)\n",
    "\n",
    "# W, b\n",
    "W = tf.Variable(tf.random_normal([2,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# H\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, labels=Y))\n",
    "\n",
    "# train\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1 )\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(30000):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X: x_data,\n",
    "                                                     Y: y_data})\n",
    "    if step % 3000 == 0:\n",
    "        print(f'cost값은:{cost_val}')\n",
    "\n",
    "# prediction\n",
    "predict = tf.cast(H>0.5, tf.float32)\n",
    "sess.run(predict, feed_dict={X:[[0,0]]})\n",
    "\n",
    "\n",
    "# or gate는 위의 y_data를 바꿔주면됨\n",
    "\n",
    "# 해보면 or, and gate 모두 가능\n",
    "# 컴퓨터의 기본 논리회로는 다음과 같고 가능하다는것을 확인함\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic이란 구분 선을 긋는거라고 하였음\n",
    "# 그리고 가능하다는 것을 확인, 진리표\n",
    "\n",
    "# 그런데 XOR gate는 logistic처럼 금을 그어서 나눌 수없ㅇ므\n",
    "# 올바른 결과 가 안나옴\n",
    "# 그럼 이를 코드로 한번확인해보자\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost값은:0.7368353605270386\n",
      "cost값은:0.6931471824645996\n",
      "cost값은:0.6931471824645996\n",
      "cost값은:0.6931471824645996\n",
      "cost값은:0.6931471824645996\n",
      "cost값은:0.6931471824645996\n",
      "cost값은:0.6931471824645996\n",
      "cost값은:0.6931471824645996\n",
      "cost값은:0.6931471824645996\n",
      "cost값은:0.6931471824645996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 두개가 같을때 0, 다를때 1\n",
    "# X or gate\n",
    "x_data = [[0,0],\n",
    "         [0,1],\n",
    "         [1,0],\n",
    "         [1,1]]\n",
    "y_data = [[0],\n",
    "         [1],\n",
    "         [1],\n",
    "         [0]]\n",
    "\n",
    "# X, Y\n",
    "X = tf.placeholder(shape=(None,2), dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=(None,1), dtype=tf.float32)\n",
    "\n",
    "# W, b\n",
    "W = tf.Variable(tf.random_normal([2,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# H\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, labels=Y))\n",
    "\n",
    "# train\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1 )\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(30000):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X: x_data,\n",
    "                                                     Y: y_data})\n",
    "    if step % 3000 == 0:\n",
    "        print(f'cost값은:{cost_val}')\n",
    "\n",
    "# prediction\n",
    "predict = tf.cast(H>0.5, tf.float32)\n",
    "sess.run(predict, feed_dict={X:[[0,0]]})\n",
    "\n",
    "# 00 녛으면 0 나와야 되는데 \n",
    "# array([[1.]], dtype=float32)\n",
    "# 1이 나옴: logistic으로 xor gate 구현 불가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perceptron(logistic: 학습이 가능)으로 AND/OR는 구현이 가능\n",
    "# 컴퓨터를 논리 회로가 AND/OR gate와 같이 되어 있기에 구현을 하고자 한 것\n",
    "# 그런데 XOR(exclusive)는 perceptron으로 구현이 안되요\n",
    "# 즉, 학습이 안됨\n",
    "# 모든 회로를 perceptron으로 만들 수 있으면 이를 모아서 칩을 만들면 되는데\n",
    "# xor 때문에 제동이 걸림\n",
    "# 많은 사람들이 xor을 어떻게 perceptron으로 구현할 수있을지 매달림\n",
    "# 그래야 각 논리회로를 perceptron으로 구현해서 인공 신경망을 만들 수있기 때문\n",
    "\n",
    "# 학습이 가능한 perceptron으로 논리회로를 구현해야 학습이 가능한 인공 신경망을 구햔할 수 있음\n",
    "\n",
    "\n",
    "# 1969에 마빈 민스키라는 사람이 논문ㅇ을 하나 발표\n",
    "# MIT AI lab 창시자\n",
    "# XOR는 한개의 preceptron으로 학습이 불가능하다고 수학적으로 증명하여 발표함\n",
    "# MLP(multi layer perceptron)으로는 (학습)가능하다고 함\n",
    "# 마지막으로, MLP는 학습이 너무 어려워서 지구상에 닜는 누구라도 이 학습을 시킬 수가 없어\n",
    "# meaning impossible\n",
    "# 그래서 70년대에 AI가 침체기에 들어감\n",
    "\n",
    "# 1974년도 Paul이라는박사과정 학생이 Backpropagation이라는 방법을 고안\n",
    "# 그러나 이미 사람들의 관심은 식음\n",
    "# 1982년도 다시 논문 발표, 민스키 교수 찾아감(접음)\n",
    "# 1986년도 Hinton 교수가 backpropagation에 살을 붙여서 논문 발표\n",
    "# 사람들의 관심이 돌아옴, AI 활활타오름\n",
    "\n",
    "# 1995년 쯤에는 Backpropagation방식이 안되는건 아닌데 복잡한 문제는 역시 안된다는 것을 인식\n",
    "# 이 시기에 다른 여러 알고히즘이나오기 시작함\n",
    "# SVM, 나이브베이지언,Decison Tree 등\n",
    "# LeCUN ->다른 알고리즘이 더 우수하다는 것을 증명하고 다시 침체기\n",
    "# 신경망의흥망성쇠\n",
    "\n",
    "# 캐나다에 설립된 국책연구기관: Canadian Institute for advanced research(CIFAR)\n",
    "# 국책이다보니 돈이 안되는 연구더라도 미래를 위해 지원을 해줌\n",
    "# Hinton 교수가 1978년에 캐나다로 넘어감\n",
    "# AI 연구 지속\n",
    "# 2006, 2007년도에 2개의 논문을 발표\n",
    "# 망했던 이유를 찾아서 수학적으로 증명: backpropagation이 안됬던 이유\n",
    "# 2006년도: w, b의 초기 값을 random으로 주면 안된다고 주장, 값을 잘 주면 학습할 수 있다고 주장\n",
    "# 2007년도: 초기값에 대한 증명에 대한 논문, lager를 더 많이 사용할 수록 복잡한 문제를 해결할 수 있다 주장\n",
    "# 하지만 사람들의 반응은 싸늘: 이미 부정적인 이미지가 각인이 되어있음\n",
    "# 신분세탁... rebranding!\n",
    "# to .... 딥러닝!\n",
    "# 사실상 이전부터 존재했던 neuron network...\n",
    "# 그래서 \n",
    "\n",
    "\n",
    "# AI를 기반으로 한 서비스가 이제 막 나오고 있음\n",
    "# 가장 기본적인 것이 바로 서비스 추천: 넷플렉스\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한마디로 logistic 여러개가 모인 것 = deep learning\n",
    "\n",
    "# 여러 개를 모아 네트워크를 구성하여 교육"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중계층\n",
    "# multilayer\n",
    "# https://bcho.tistory.com/1147"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중계층 개념을 코드로 때려 넣을 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost값은:0.8544375896453857\n",
      "cost값은:0.482330858707428\n",
      "cost값은:0.040052928030490875\n",
      "cost값은:0.018248548731207848\n",
      "cost값은:0.011669149622321129\n",
      "cost값은:0.008541891351342201\n",
      "cost값은:0.00672385236248374\n",
      "cost값은:0.005538139026612043\n",
      "cost값은:0.004704924300312996\n",
      "cost값은:0.004087945446372032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xor logistic 1개짜리 였음\n",
    "# 총 3개로 이루어지는 것을 표현할 것\n",
    "\n",
    "x_data = [[0,0],\n",
    "         [0,1],\n",
    "         [1,0],\n",
    "         [1,1]]\n",
    "y_data = [[0],\n",
    "         [1],\n",
    "         [1],\n",
    "         [0]]\n",
    "\n",
    "# X, Y\n",
    "X = tf.placeholder(shape=(None,2), dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=(None,1), dtype=tf.float32)\n",
    "\n",
    "# W, b\n",
    "# 다시 logistic을 수행하기 위해서는 y값이 2개가 나와야 다음 x로 들어가서 수행 가능\n",
    "# 다라서 [2,2] , [2]크기로 냄\n",
    "\n",
    "# n은 처음 logistic의 갯수\n",
    "# 다음 레이어가 없다면 1개로 나올 것\n",
    "# 레이어를 많이 줄수록 코스트 값은 낮아질 수앖에 없음\n",
    "# 대신 메모리 사용량이 문제: 시간이 오래 걸림: 매트릭스 곱셈을 다 수행하는 것이기 때문\n",
    "# 수치 연산에 특화된 gpu가 더 빠름\n",
    "# W1 = tf.Variable(tf.random_normal([2,n]), name='weight1')\n",
    "# b1 = tf.Variable(tf.random_normal([n]), name='bias1')\n",
    "# W2 = tf.Variable(tf.random_normal([n,1]), name='weight2')\n",
    "# b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "\n",
    "# 처음 실행 layer 갯수 말고 이후의 layer 갯수를 늘여주려면?\n",
    "# W3, b3 까지 설정하면됨\n",
    "\n",
    "# 학습횟수 늘이는 것과의 차이?\n",
    "# logistic 갯수 늘이는 것과 layer 갯수 늘이는 것의 차이?\n",
    "# depth가 늘어가는 것: layer가 늘어나는 것:  뒤로 값이 넘어갈수록 정확하기는 하지만, 너무 많아지만 오히려 안좋은 현상 발생\n",
    "# 둘다 무조건 많다고 좋은 것은 아님\n",
    "\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2,2]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X,W1)+b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([2,1]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "\n",
    "# H\n",
    "logit = tf.matmul(layer1,W2) + b2\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, labels=Y))\n",
    "\n",
    "# train\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1 )\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(30000):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X: x_data,\n",
    "                                                     Y: y_data})\n",
    "    if step % 3000 == 0:\n",
    "        print(f'cost값은:{cost_val}')\n",
    "\n",
    "# prediction\n",
    "predict = tf.cast(H>0.5, tf.float32)\n",
    "sess.run(predict, feed_dict={X:[[0,0]]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1월 13일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST with Neural Network(Deep learning)\n",
    "# tensorflow가 기본으로 제공해주는 예제를 이용해서 구현해 보아요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module 삽입\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# data loading\n",
    "mnist = input_data.read_data_sets('./data/mnist', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder\n",
    "X = tf.placeholder(shape=[None, 784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n",
    "\n",
    "\n",
    "# W,b: deep learning을 위해 여러 layer, loogistics를 만들 것 (deep&wide)\n",
    "# 처음 layer의 logistic은 256개, bias도 따라가야 됨\n",
    "W1 = tf.Variable(tf.random_normal(shape=[784,256]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal(shape=[256]), name='bias1')\n",
    "\n",
    "# 앞의 layer에서 나온 값이 sigmoid 된 값이 다음 layer에 들어가게 된다.\n",
    "layer1 = tf.sigmoid(tf.matmul(X,W1) + b1)\n",
    "\n",
    "# 두번째 layer 생성\n",
    "W2 = tf.Variable(tf.random_normal(shape=[256, 256]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal(shape=[256]), name='bias2')\n",
    "layer2 = tf.sigmoid(tf.matmul(layer1,W2) + b2)\n",
    "\n",
    "# 세번째 layer 생성\n",
    "W3 = tf.Variable(tf.random_normal(shape=[256, 10]), name='weight3')\n",
    "b3 = tf.Variable(tf.random_normal(shape=[10]), name='bias3')\n",
    "\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(layer2, W3) + b3\n",
    "H = tf.nn.softmax(logit)\n",
    "# sigmoid를 쓰면 각각의 확률이 나오고, softmax는 전체에 대한 확률이 나옴\n",
    "# 아직까지는 두 개가 큰 상관이 없음(그래도 배운대로 사용하기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: 0.006717005744576454\n",
      "cost: 0.005443883128464222\n",
      "cost: 0.004832758568227291\n",
      "cost: 0.003539436962455511\n",
      "cost: 0.0038376478478312492\n",
      "cost: 0.0033806234132498503\n",
      "cost: 0.003093603067100048\n",
      "cost: 0.0024836650118231773\n",
      "cost: 0.0026076033245772123\n",
      "cost: 0.0028986611869186163\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "num_of_epoch = 30\n",
    "batch_size = 100\n",
    "\n",
    "for step in range(num_of_epoch):\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "    cost_val = 0\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        num_of_iter = int(mnist.train.num_examples / batch_size)\n",
    "        _, cost_val = sess.run([train, cost], feed_dict={X: batch_x,\n",
    "                                                    Y: batch_y})\n",
    "    if step % 3 == 0:\n",
    "        print(f'cost: {cost_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:0.7752000093460083\n"
     ]
    }
   ],
   "source": [
    "# acuracy\n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(f'정확도:{sess.run(accuracy, feed_dict={X:mnist.test.images, Y: mnist.test.labels})}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생각보다 정확도가 많이 향상되지 않았어요!\n",
    "# Hinton이 그 원인을 파악하려고 노력!\n",
    "# deep learning은 조금 더 학습이 잘 되기 위해 layer를 추가하고\n",
    "# 각 layer에 많은 perceptron을 추가해서 구현\n",
    "\n",
    "# 0과1로 표현되는 값들은 linear로 표현하면 안된다는 것을 알고, 지수함수의 역함수(sigmoid)\n",
    "# 시그모이드 함수에서는 0-1사이의 수로 떨어짐\n",
    "# 그말은 즉, 확률로 나옴\n",
    "# multinomial로 넘어오면 여러 확률값이 나옴: 그래서 softmax 를 만들어냄\n",
    "# softmax를 통해 여러 logistic 각각에 대한 확률을 구할 수 있게 됨\n",
    "# layer가 많아지면 만ㅎ아질수록, 시그모이드를 진행하면 값이 희미해진다. 0에 가까워진다.\n",
    "\n",
    "# 함수를 하나 만들어 냄: ReLu\n",
    "# multilayer가 되면 위의 이유로 시그모이드가 중첩이 되는것이 좋지 않음\n",
    "# 멀티레이어에서는 그래서 시그모이드 대신에 relu사용\n",
    "# https://reniew.github.io/12/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: 1.19209286886246e-09\n",
      "cost: 1.0251946491734998e-07\n",
      "cost: 0.0\n",
      "cost: 0.0\n",
      "cost: 0.0\n",
      "cost: 0.0\n",
      "cost: 0.0\n",
      "cost: 5.960462790000065e-09\n",
      "cost: 0.0\n",
      "cost: 0.0\n",
      "정확도:0.7789000272750854\n"
     ]
    }
   ],
   "source": [
    "# 위의 과정을 relu로 구현해보기\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None, 784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n",
    "\n",
    "\n",
    "# W,b\n",
    "W1 = tf.Variable(tf.random_normal(shape=[784,256]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal(shape=[256]), name='bias1')\n",
    "# relu!!!!!!사용1!!!!! 수식은 너무 복잡해서 주어진 함수사용\n",
    "layer1 = tf.nn.relu(tf.matmul(X,W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal(shape=[256, 256]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal(shape=[256]), name='bias2')\n",
    "layer2 = tf.nn.relu(tf.matmul(layer1,W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal(shape=[256, 10]), name='weight3')\n",
    "b3 = tf.Variable(tf.random_normal(shape=[10]), name='bias3')\n",
    "\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(layer2, W3) + b3\n",
    "H = tf.nn.softmax(logit)\n",
    "\n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=Y))\n",
    "\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "# 학습\n",
    "num_of_epoch = 30\n",
    "batch_size = 100\n",
    "\n",
    "for step in range(num_of_epoch):\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "    cost_val = 0\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        num_of_iter = int(mnist.train.num_examples / batch_size)\n",
    "        _, cost_val = sess.run([train, cost], feed_dict={X: batch_x,\n",
    "                                                    Y: batch_y})\n",
    "    if step % 3 == 0:\n",
    "        print(f'cost: {cost_val}')\n",
    "     \n",
    "    \n",
    "# acuracy\n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(f'정확도:{sess.run(accuracy, feed_dict={X:mnist.test.images, Y: mnist.test.labels})}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leru 함수를 사용하는데... 그래도 여전히 정확도가 낮거나 높거나 왔다갔다 편차가 심함\n",
    "# 왜그러지?\n",
    "# 초기값의 문제! 초기값을 랜덤으로 주는 것이 문제!\n",
    "# 운이 좋으면 초기 W값에 따라 학습이 잘 이ㄹ어지고, 그렇지 않은경우에느 ... 망함 ㅋㅋ\n",
    "\n",
    "# Hinton 교수가 중요하게 여기는 또 하나의 요건은 초기값\n",
    "# 2010년도 Xavier 초기화라는 방식이 논문으로 발표!\n",
    "\n",
    "# 2015년도  He's 초기화라는 방식이 논문으로 발표!\n",
    "# 현재에도 계속 연구 진행!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias는 상수여서 그냥 잡아도 괜찮지만,w는 중요\n",
    "# 다음과 같이 변환\n",
    "\n",
    "# W = tf.Variable(tf.random_normal(shape=[784,256]), name='weight1')\n",
    "# W = tf.get_variable(\"weight1\", shape=[784,256], initializer=tf.contrib.layers.xavier_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "cost: 0.1076035127043724\n",
      "cost: 0.1758366972208023\n",
      "cost: 0.14722779393196106\n",
      "cost: 0.05936460942029953\n",
      "cost: 0.06703907996416092\n",
      "cost: 0.12409331649541855\n",
      "cost: 0.0065984767861664295\n",
      "cost: 0.01930631697177887\n",
      "cost: 0.011265676468610764\n",
      "cost: 0.001069576246663928\n",
      "정확도:0.9728000164031982\n"
     ]
    }
   ],
   "source": [
    "# 위의 과정을 relu로 구현해보기\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "# data loading\n",
    "mnist = input_data.read_data_sets('./data/mnist', one_hot=True)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None, 784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n",
    "\n",
    "\n",
    "# W,b\n",
    "W1 = tf.get_variable(\"weight1\", shape=[784,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal(shape=[256]), name='bias1')\n",
    "# relu!!!!!!사용1!!!!! 수식은 너무 복잡해서 주어진 함수사용\n",
    "layer1 = tf.nn.relu(tf.matmul(X,W1) + b1)\n",
    "\n",
    "W2 = tf.get_variable(\"weight2\", shape=[256,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal(shape=[256]), name='bias2')\n",
    "layer2 = tf.nn.relu(tf.matmul(layer1,W2) + b2)\n",
    "\n",
    "W3 = tf.get_variable(\"weight3\", shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal(shape=[10]), name='bias3')\n",
    "\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(layer2, W3) + b3\n",
    "H = tf.nn.relu(logit)\n",
    "\n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=Y))\n",
    "\n",
    "\n",
    "# train\n",
    "# AdamOptimizer 사용\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "# 학습\n",
    "num_of_epoch = 30\n",
    "batch_size = 100\n",
    "\n",
    "for step in range(num_of_epoch):    \n",
    "    num_of_iter = int(mnist.train.num_examples / batch_size)\n",
    "    cost_val = 0\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, cost_val = sess.run([train, cost], feed_dict={X: batch_x,\n",
    "                                                    Y: batch_y})\n",
    "    if step % 3 == 0:\n",
    "        print(f'cost: {cost_val}')\n",
    "     \n",
    "    \n",
    "# acuracy\n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(f'정확도:{sess.run(accuracy, feed_dict={X:mnist.test.images, Y: mnist.test.labels})}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nn이 붙는 것은 neuron network: deep learning에서 사용하는 것\n",
    "## logistic; multinomial 을 기준으로 잡고 이야기하고 있음\n",
    "## 이전에 한 부분도 get_variable을 이용하면 됨\n",
    "\n",
    "# 맘찬가지로 더 성능 좋은 알고리즘들이 나오고 있음\n",
    "#AdamOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타이타닉 이것으로 한번 해보기!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfitting (과적합)\n",
    "\n",
    "# 학습한 모델이 training data set에 최적화되어 있는 상태\n",
    "# 테스트 데이터에는 잘 들어맞지 않는 상태를 지칭함\n",
    "# 학습한 모델이 training data set에는 약 98%이상 정확도를 가지지만\n",
    "# test data set에 대해서는 85%정도 수준으로 정확도가 나오면 overfitting\n",
    "\n",
    "\n",
    "# feature engineering 과정에서 ...\n",
    "# 1. 일단 학습하는 데이터 수가 많아야 함 (개인적으로 제어 가능한 영역은 아님)\n",
    "# 2. 필요없는 feature(column)들은 학습에서 제외!\n",
    "# 3. 마찬가지로 중복되는 feature 또한 합치거나 단일화 시켜줘야 한다.\n",
    "\n",
    "# 학습하는 과정에서...\n",
    "# 사람들이 연구하는 과정에서 2014년 논문이 하나 발표된다.\n",
    "# 모든 perceptron이 학습에 참여하기 때문에 oerfitting이 발생한다고 보았고,\n",
    "# overfitting을 피하기 위해서는 일부 logistic만 이용하면 된다고 생각한 것\n",
    "# 모든 logistic을 이용하면 굉장히 빡빡하게 만들어진다고 본 것\n",
    "# 이 방식을 dropout 방식이라 부름\n",
    "# 30% 죽이고 70% 가지고 학습하자는 그런 의미(정교하지 않고 대충 그려지는 ..)\n",
    "# tensorflow에서 하나의 함수 형태로 제공해줌\n",
    "# 위에서 똑같은 과정을 이 함수를 이용해볼 것\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: 0.5381122827529907\n",
      "cost: 0.1639564335346222\n",
      "cost: 0.3174959421157837\n",
      "cost: 0.10470154136419296\n",
      "cost: 0.13995122909545898\n",
      "cost: 0.062187694013118744\n",
      "cost: 0.1638113558292389\n",
      "cost: 0.17080189287662506\n",
      "cost: 0.3401457667350769\n",
      "cost: 0.06359534710645676\n",
      "정확도:0.9635999798774719\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None, 784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n",
    "dout_rate = tf.placeholder(dtype=tf.float32)\n",
    "# 값이 하나, scalar이기 때문에 shape은 안적어도 괜찮!\n",
    "\n",
    "\n",
    "# W,b\n",
    "W1 = tf.get_variable(\"weight1\", shape=[784,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal(shape=[256]), name='bias1')\n",
    "# dropout 사용!!!\n",
    "# _layer1에 대해서 deopout을 이용해 일부를 꺼버림, 동작을 시키지 않음\n",
    "# 어떤 비율로 동작을 시키지 않을 것인지 rate로 정해줌: 0.3 = 30% 죽인다는 의미\n",
    "# 30% 죽여서 넘김\n",
    "_layer1 = tf.nn.relu(tf.matmul(X,W1) + b1)\n",
    "# layer1 = tf.nn.dropout(_layer1, rate=0.3)\n",
    "# 다만, 이를 일일이 적지 않고 새로운 placeholder로 준다.\n",
    "layer1 = tf.nn.dropout(_layer1, rate=dout_rate)\n",
    "\n",
    "\n",
    "W2 = tf.get_variable(\"weight2\", shape=[256,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal(shape=[256]), name='bias2')\n",
    "_layer2 = tf.nn.relu(tf.matmul(layer1,W2) + b2)\n",
    "layer2 = tf.nn.dropout(_layer2, rate=dout_rate)\n",
    "\n",
    "W3 = tf.get_variable(\"weight3\", shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal(shape=[10]), name='bias3')\n",
    "\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(layer2, W3) + b3\n",
    "H = tf.nn.relu(logit)\n",
    "\n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=Y))\n",
    "\n",
    "\n",
    "# train\n",
    "# AdamOptimizer 사용\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "# 학습\n",
    "num_of_epoch = 30\n",
    "batch_size = 100\n",
    "\n",
    "for step in range(num_of_epoch):    \n",
    "    num_of_iter = int(mnist.train.num_examples / batch_size)\n",
    "    cost_val = 0\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, cost_val = sess.run([train, cost], feed_dict={X: batch_x,\n",
    "                                                    Y: batch_y,\n",
    "                                                        dout_rate: 0.3})\n",
    "    if step % 3 == 0:\n",
    "        print(f'cost: {cost_val}')\n",
    "     \n",
    "    \n",
    "    \n",
    "# 중요한것! 학습 시에는 droupout을 사용하여 일부 node를 끄고 하지만(overfitting 피하기 위해),\n",
    "# a마지막 test 할 때에는 모두 다 키고 해야함! (dropout rate=0으로 잡아야 함)\n",
    "\n",
    "    \n",
    "# acuracy\n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(f'정확도:{sess.run(accuracy, feed_dict={X:mnist.test.images, Y: mnist.test.labels,dout_rate: 0})}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기화\n",
    "# relu\n",
    "# dropout \n",
    "\n",
    "# 이 세가지!! 유의\n",
    "# 모든 deep learning에서 다 들어가야 하는 과정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 이후에도 정확도를 더 올리려면 이제 다른 방법을 사용해야 함\n",
    "# cnn, 앙상블\n",
    "\n",
    "# 사람들이 연구를 했는데, 이미지 처리는 이렇게 하는 것이 옳은 것 같다고 새로 발표\n",
    "# 내일 이어서 할 것 \n",
    "\n",
    "\n",
    "# 지금까지 지도학습 중 이미지처리를 가지고 해본 것!\n",
    "# 이제 이 내용을 가지고 다른 내용도 개인적으로 공부해야함\n",
    "# 비지도학습, clustering...etc\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[GPU_ENV]",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
