{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 지금까지 배운 모든 내용을 가지고 tesnsorflow에서 제공하는 mnist 데이터를 가지고 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 삽입\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# data loading \n",
    "\n",
    "mnist = input_data.read_data_sets('./data/mnist', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 초기화\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder\n",
    "\n",
    "X = tf.placeholder(shape = [None, 784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape = [None, 10], dtype=tf.float32)\n",
    "keep_rate = tf.placeholder(dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution layer 설정\n",
    "#### 만약 데이터 전처리 및 test, train data 분할 과정이 필요하다면 이전에 완료해야 함!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image data 설정\n",
    "\n",
    "x_img = tf.reshape(X, [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 7, 7, 64)\n"
     ]
    }
   ],
   "source": [
    "# filter\n",
    "\n",
    "# width, height, depth: image와 맞춰줌, filter 개수: 임의 설정\n",
    "F1 = tf.Variable(tf.random_normal([3,3,1,32]), name ='Filter1')\n",
    "L1 = tf.nn.conv2d(x_img,\n",
    "                  F1,\n",
    "                  strides=[1,1,1,1],\n",
    "                  padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1,\n",
    "                    ksize=[1,2,2,1],\n",
    "                    strides=[1,2,2,1],\n",
    "                    padding='SAME')\n",
    "\n",
    "\n",
    "F2 = tf.Variable(tf.random_normal([3,3,32,64]), name ='Filter2')\n",
    "L2 = tf.nn.conv2d(L1,\n",
    "                  F2,\n",
    "                  strides=[1,1,1,1],\n",
    "                  padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2,\n",
    "                    ksize=[1,2,2,1],\n",
    "                    strides=[1,2,2,1],\n",
    "                    padding='SAME')\n",
    "print(L2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-layer multinomial logistic regression 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 3136)\n"
     ]
    }
   ],
   "source": [
    "# 위의 값을 2차원으로 변환\n",
    "\n",
    "L2 = tf.reshape(L2, [-1, 7*7*64])\n",
    "conv = L2\n",
    "print(conv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-layer 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.get_variable(\"weight1\", \n",
    "                     shape = [7*7*64,256],  #256은 임의의 logistic 노드 갯수\n",
    "                     initializer = tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal(shape = [256]), name = 'bias1')\n",
    "\n",
    "_layer1 = tf.nn.relu(tf.matmul(conv, W1) + b1)\n",
    "layer1 = tf.nn.dropout(_layer1, keep_prob = keep_rate)  \n",
    "\n",
    "# keep_prob: 노드를 살릴 확률\n",
    "# 버전이 올라가면서 rate: 노드를 죽일 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.get_variable(\"weight2\", \n",
    "                     shape = [256,10],  #최종 값은 label의 갯수: 10\n",
    "                     initializer = tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal(shape = [10]), name = 'bias2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis\n",
    "\n",
    "logit = tf.matmul(layer1, W2) + b2\n",
    "H = tf.nn.relu(logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logit,\n",
    "                                                                 labels = Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session, 초기화\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost값: 0.4190565049648285\n",
      "cost값: 0.2415105104446411\n",
      "cost값: 0.28697383403778076\n",
      "cost값: 0.17715726792812347\n",
      "cost값: 0.11836536228656769\n",
      "cost값: 0.04389975592494011\n",
      "cost값: 0.19270513951778412\n",
      "cost값: 0.1926712989807129\n",
      "cost값: 0.16013790667057037\n",
      "cost값: 0.16698910295963287\n",
      "cost값: 0.05905570834875107\n",
      "cost값: 0.010394926182925701\n",
      "cost값: 0.059021785855293274\n",
      "cost값: 0.01400727964937687\n",
      "cost값: 0.04886467754840851\n",
      "cost값: 0.01665341481566429\n",
      "cost값: 0.3109450340270996\n",
      "cost값: 0.035629305988550186\n",
      "cost값: 0.011684360913932323\n",
      "cost값: 0.01017034612596035\n",
      "cost값: 0.006488056853413582\n",
      "cost값: 0.04088509455323219\n",
      "cost값: 0.020686347037553787\n",
      "cost값: 0.022999031469225883\n",
      "cost값: 0.08725320547819138\n",
      "cost값: 0.034166086465120316\n",
      "cost값: 0.002041315659880638\n",
      "cost값: 0.03405172377824783\n",
      "cost값: 0.03294956311583519\n",
      "cost값: 0.001109772827476263\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "\n",
    "num_of_epoch = 30\n",
    "batch_size = 100\n",
    "\n",
    "for step in range(num_of_epoch):\n",
    "    num_of_iter = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, val_cost = sess.run([train, cost],\n",
    "                               feed_dict = {X: batch_x,\n",
    "                                            Y: batch_y,\n",
    "                                            keep_rate: 0.7})\n",
    "    if step % 1 == 0:\n",
    "        print(f'cost값: {val_cost}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9867"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도\n",
    "\n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32 ))\n",
    "\n",
    "sess.run(accuracy, feed_dict = {X: mnist.test.images,\n",
    "                                Y: mnist.test.labels,\n",
    "                                keep_rate: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[CPU_ENV]",
   "language": "python",
   "name": "cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
